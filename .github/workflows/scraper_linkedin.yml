name: Scrape Linkedin
on:
  schedule:
    - cron: '0 12 * * *'
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checking out repo
        uses: actions/checkout@v3
      - name: Setting up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Installing package list
        run: apt list --installed    
      - name: Removing previous chrome instances on runner 
        run: sudo apt purge google-chrome-stable  
        
       # Need to fetch reqs if needed
      - name: Installing all necessary packages
        run: pip install pandas chromedriver-autoinstaller selenium pyvirtualdisplay webdriver_manager linkedin_jobs_scraper
      - name: Install xvfb
        run: sudo apt-get install xvfb

      - name: Running the Python script
        run: python online_scraper.py
        
      - name: Commit files
        run: |
          git config --local user.name github-actions
          git config --local user.email "actions@github.com"
          git add -A
          git diff-index --quiet HEAD || git commit -m 'update'
        env:
          REPO_KEY: ${{secrets.GITHUB_TOKEN}}
          username: github-actions
          
      - name: push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main  


# git add data/*
# git commit -am "GH ACTION Autorun $(date)"
# git push origin main
